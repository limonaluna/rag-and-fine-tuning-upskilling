# RAG and Fine-Tuning Upskilling Workshop
This repository is designed to support hands-on learning and upskilling in **Retrieval-Augmented Generation (RAG)** and **Fine-Tuning of Large Language Models (LLMs)** with Azure OpenAI and Azure AI Search. It includes detailed setup instructions, practical notebooks and guided experiences to help you build, customize, and optimize GenAI applications using Microsoft Azure.

## ðŸ“š Whatâ€™s Inside
This upskilling repo is **based on and extends** the following Microsoft resources:

* [RAG Time](https://github.com/microsoft/rag-time) by Microsoft
* [LLM-Fine-Tuning-Azure](https://github.com/microsoft/LLM-Fine-Tuning-Azure/tree/main) by Microsoft.

The content has been adapted and enriched to provide a smoother and more guided learning experience, ideal for workshops or self-paced exploration.

## ðŸ“ Repository Structure

### **01 â€“ Azure Resource Setup**  
ðŸ§± **Foundation for Everything**  
Before doing anything else, youâ€™ll need to set up the essential Azure services: **Azure OpenAI**, **Azure AI Search**, and **Azure Storage**.  
This step lays the groundwork for all following steps.

> ðŸ”§ **To Do:** Manual, no-code setup using the Azure Portal.

---

### **02 â€“ Azure AI Search Quickstart**  
ðŸ” **Index Setup with Vectorization**  
Use the **Import and vectorize data** wizard in the Azure Portal to create an AI Search index.  
This wizard chunks your content and uses an embedding model to vectorize it â€” both during indexing and querying.

> âœ… **Required for:** Step 04 and Step 05  
> ðŸ”§ **To Do:** Manual, no-code setup using the Azure Portal.

---

### **03 â€“ Code Environment Setup**  
ðŸ’» **Prepare Your Code Environment**  
Set up your Python environment to run the code-based exercises. You can do this locally, in a virtual environment, or using GitHub Codespaces.

> âœ… **Required for:** Step 04 and Step 05  
> ðŸ”§ **To Do:** Choose your preferred setup (local, virtual env, or Codespaces).

---

### **04 â€“ RAG Fundamentals**  
ðŸ¤– **Hands-On with Retrieval-Augmented Generation (RAG)**  
This notebook demonstrates how to use **Azure OpenAI** and **Azure AI Search** together to retrieve relevant documents and generate answers using a RAG approach.

> âœ… **Prerequisites:** Steps 01, 02, and 03  
> ðŸ§ª **To Do:** Follow the notebook and complete the built-in challenges (code-first experience).

---

### **05 â€“ Optimizing Retrieval**  
ðŸš€ **Take Retrieval to the Next Level**  
This notebook builds on RAG Fundamentals and explores **different search strategies**: keyword, vector, hybrid, semantic ranking, and query rewriting.

> âœ… **Prerequisites:** Steps 01, 02, and 03  
> ðŸ§ª **To Do:** Follow the notebook and complete the built-in challenges (code-first experience).

---

### **07 â€“ LLM Fine-Tuning**  
ðŸŽ¯ **Fine-Tune GPT Models with Azure OpenAI**  
This is a standalone step focused on using the **Azure OpenAI Studio** to fine-tune a language model (no RAG setup required).

> âœ… **Only requires:** Step 01 (Azure setup)  
> ðŸ”§ **To Do:** Use the Azure AI Foundry experience in the Portal (no-code).


## ðŸ”§ Requirements
* An Azure subscription with permission to deploy resources and configure authentication:
    * Azure OpenAI
    * Azure Cognitive Search
    * Azure Storage

* Basic familiarity with Python and LLMs
* Access to Github Codespaces or possibility to run code on VS Code

## ðŸš€ Get Started
* To begin, follow the instructions in 01_AzureResourceSetup.md.
* Each notebook is self-contained and walks you through code, configuration, and explanations.

## ðŸ“Œ Notes
* This repo is for educational and prototyping purposes and is not production-hardened.
* You may need to request access to Azure OpenAI via the Azure OpenAI portal.

## ðŸ™Œ Acknowledgments
This work builds upon:
* [RAG Time](https://github.com/microsoft/rag-time) by Microsoft
* [LLM-Fine-Tuning-Azure](https://github.com/microsoft/LLM-Fine-Tuning-Azure/tree/main) by Microsoft